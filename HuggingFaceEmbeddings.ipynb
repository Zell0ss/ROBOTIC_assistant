{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "FAQ_CHROMA_PATH=\"chroma_data\"\n",
    "\n",
    "#load myiam\n",
    "with open(\"documents/myiam.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Chunk the text\n",
    "splitter = MarkdownTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Merge headers with content\n",
    "documents = []\n",
    "for chunk in chunks: \n",
    "    header = chunk.split('\\n')[0]  # Assuming header is followed by /n\n",
    "    documents.append(Document(page_content=chunk, metadata={\"header\": header, \"category\": \"MyIAM\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PO\n",
    "with open(\"documents/product_owner.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Chunk the text\n",
    "splitter = MarkdownTextSplitter(chunk_size=1024, chunk_overlap=50)\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Merge headers with content\n",
    "for chunk in chunks:  \n",
    "    header = chunk.split('\\n')[0]\n",
    "    documents.append(Document(page_content=chunk, metadata={\"header\": header, \"category\": \"PO\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingfaceembeddings downloads the model the first time and then it uses it locally, but we want it in local from the get to go. You need sentence-transformers pip installed to use them.\n",
    "\n",
    "For getting the model locally you can go to \n",
    "- [https://huggingface.co/sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)  Better quality but slower: 1m 32 seconds\n",
    "- [https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)  Fast and lightweight: 4 segs\n",
    "\n",
    "Click \"Files and versions\" tab\n",
    "Download all the files to a local directory WITH GIT LFS \n",
    "```shell\n",
    "./models/all-MiniLM-L6-v2/\n",
    "├── config.json\n",
    "├── pytorch_model.bin\n",
    "├── tokenizer.json\n",
    "├── tokenizer_config.json\n",
    "├── vocab.txt\n",
    "└── modules.json\n",
    "```\n",
    "### with sentence-transformers directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"./models/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create wrapper for LangChain\n",
    "class LocalEmbeddings:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return self.model.encode(texts, convert_to_tensor=False).tolist()\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self.model.encode([text], convert_to_tensor=False)[0].tolist()\n",
    "\n",
    "embeddings = LocalEmbeddings(model)\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=FAQ_CHROMA_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "# MODEL_NAME=\"./models/all-MiniLM-L6-v2\"\n",
    "MODEL_NAME=\"./models/all-mpnet-base-v2\"\n",
    "\n",
    "# Initialize local embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_NAME, \n",
    "    model_kwargs={'device': 'cpu'}  # or 'cuda' if you have GPU \n",
    ")\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=FAQ_CHROMA_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try some for size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Products and subscriptions\n",
      "ROBOTIC team is responsible for designing and managing DPI (the product library and action broker) and VANISH (the orchestrator).\n",
      "The PO uses these tools to define and manage their own products, as varied as Linux VM with an Apache server installed, an AVI, or an extra Linux Administrative account. A subscription is an instance of a product requested and owned by an user. It is created, destroyed and managed by its requester using the Vanish flows defined by the PO. Subscriptions are paused during each action execution to prevent concurrent actions from being launched.\n"
     ]
    }
   ],
   "source": [
    "vector_store_db= Chroma(\n",
    "    persist_directory=FAQ_CHROMA_PATH,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# Query the vector store\n",
    "query = \"What is ROBOTIC responsability?\"\n",
    "docs = vector_store_db.similarity_search(query, k=3)\n",
    "print(docs[0].page_content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1.2 Cyberark entitlements\n",
      "Onboarded in ELDAP groups in EMEA and APAC and in AD in AMER, this entitlements grant access to servers or applications through Cyberark site. For more information, please follow the cyberark training (link at the bottom)\n",
      "Example:\n",
      "Entitlement: IV2 EMEA Cyberark ROBOTIC-TOOLS Breakglass\n",
      "ELDAP group or AD group (only for AMER Cyberark entitlements): cn=IV2EMEA_CYBERARK_IV2AROBOTTOOL_Bglass,ou=group,ou=CyberArk,ou=Applications,dc=root\n",
      "For a detailed explanation of what exact access gives each kind of entitlement (breakglass, user, dev & owner) please refer to the extended rights documentation (https://collab.cib.echonet/iandp/sites/Risk-and-Strategy/IT%20Security%20Operations/SecProd-OS-and-Services/UserGuides/SitePages/Home.aspx )\n",
      "- For Cyberark entitlements ROBOTIC can onboard only human users (UIDs) which account has been activated at least 12 hours prior\n",
      "- ROBOTIC cannot onboard here any non human account (SVC, GEN, OPS, …). The SVC and GEN accounts for managing the ecosystem and its subscriptions are already onboarded when said ecosystem/subscription is created\n",
      "- ROBOTIC also cannot onboard the Breakglass entitlement to an user that already has the User one.\n",
      "For checking ELDAP groups of an user you can use their own web site https://eldaptool.cib.echonet/ldapTools/\n"
     ]
    }
   ],
   "source": [
    "query = \"what are cyberark entitlements?\"\n",
    "docs = vector_store_db.similarity_search(query, k=3)\n",
    "print(docs[0].page_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "FAQ_CHROMA_PATH=\"chroma_data\"\n",
    "MODEL_NAME=\"./models/all-mpnet-base-v2\"\n",
    "\n",
    "# First define the system & human prompts -> chat prompt template\n",
    "roboasistant_system_template_str = \"\"\"You are a member of the robotic team. \n",
    "Your job is to answer questions about the onboarding of entitlements or the product ownership.\n",
    "Use the following context to answer questions.\n",
    "Be as detailed as possible, but don't make up any information\n",
    "that's not from the context. If you don't know an answer, say\n",
    "you don't know.\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "roboasistant_system_prompt = SystemMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        input_variables=[\"context\"], template=roboasistant_system_template_str\n",
    "    )\n",
    ")\n",
    "\n",
    "roboasistant_human_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=\"{question}\")\n",
    ")\n",
    "roboassistant_messages = [roboasistant_system_prompt, roboasistant_human_prompt]\n",
    "\n",
    "roboassistant_prompt_template = ChatPromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], messages=roboassistant_messages\n",
    ")\n",
    "\n",
    "\n",
    "# Second define the RAG chain = retriever, chat prompt template, chat model & output parser\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "embeddings  = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_NAME, #local path\n",
    "    model_kwargs={'device': 'cpu'}  # or 'cuda' if you have GPU \n",
    ")\n",
    "\n",
    "faqs_vector_db = Chroma(\n",
    "    persist_directory=FAQ_CHROMA_PATH,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "faqs_retriever = faqs_vector_db.as_retriever(k=3)\n",
    "\n",
    "faqs_roboassistant_chain = (\n",
    "    {\"context\": faqs_retriever, \"question\": RunnablePassthrough()}\n",
    "    | roboassistant_prompt_template\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In MyIAM, the ROBOTIC team is known as IV2 Manual Provisioner.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faqs_roboassistant_chain.invoke(\"what is the name of robotic in myiam?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cyberark entitlements are permissions granted to users to access servers or applications through the Cyberark site. These entitlements are onboarded in ELDAP groups in EMEA and APAC and in AD in AMER. Examples of Cyberark entitlements include \"IV2 EMEA Cyberark ROBOTIC-TOOLS Breakglass.\" Each entitlement is associated with a specific ELDAP group or AD group for AMER Cyberark entitlements. It\\'s important to note that only human users (UIDs) with activated accounts at least 12 hours prior can be onboarded for Cyberark entitlements. Additionally, certain restrictions apply, such as not onboarding non-human accounts (SVC, GEN, OPS) and not onboarding the Breakglass entitlement to a user who already has the User entitlement. For more detailed information on the access provided by each type of entitlement, users can refer to the extended rights documentation.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faqs_roboassistant_chain.invoke(\"what are the cyberark entitlements?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
